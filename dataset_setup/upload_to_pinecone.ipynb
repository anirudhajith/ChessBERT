{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCs0LpFxGOYA",
        "outputId": "e39d311a-b397-4e04-e024-9cfd7a7739ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow[and-cuda] in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (1.59.2)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]) (2.14.0)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.8.89 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.7.0.84 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_cudnn_cu11-8.7.0.84-py3-none-manylinux1_x86_64.whl (728.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m728.5/728.5 MB\u001b[0m \u001b[31m966.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.16.5 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_nccl_cu11-2.16.5-py3-none-manylinux1_x86_64.whl (210.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.3/210.3 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvcc-cu11==11.8.89 (from tensorflow[and-cuda])\n",
            "  Downloading nvidia_cuda_nvcc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (19.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorrt==8.5.3.1 (from tensorflow[and-cuda])\n",
            "  Downloading tensorrt-8.5.3.1-cp310-none-manylinux_2_17_x86_64.whl (549.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.5/549.5 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow[and-cuda]) (0.41.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow[and-cuda]) (3.2.2)\n",
            "Installing collected packages: nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvcc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, tensorrt\n",
            "Successfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvcc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-8.7.0.84 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.16.5 tensorrt-8.5.3.1\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.4\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.23.5)\n",
            "Collecting zstandard\n",
            "  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: zstandard\n",
            "Successfully installed zstandard-0.22.0\n",
            "Collecting python-chess\n",
            "  Downloading python_chess-1.999-py3-none-any.whl (1.4 kB)\n",
            "Collecting chess<2,>=1 (from python-chess)\n",
            "  Downloading chess-1.10.0-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: chess, python-chess\n",
            "Successfully installed chess-1.10.0 python-chess-1.999\n",
            "Cloning into 'chesspos'...\n",
            "remote: Enumerating objects: 1088, done.\u001b[K\n",
            "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 1088 (delta 25), reused 20 (delta 17), pack-reused 1048\u001b[K\n",
            "Receiving objects: 100% (1088/1088), 5.58 MiB | 26.81 MiB/s, done.\n",
            "Resolving deltas: 100% (657/657), done.\n",
            "Processing ./chesspos\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: chesspos\n",
            "  Building wheel for chesspos (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chesspos: filename=chesspos-0.1.2-py3-none-any.whl size=27170 sha256=73709a3a9301c6c2cc98cc0806c8a6acd99231501000fe964aaad2d9b82a1297\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-34o8_ufb/wheels/ff/c3/0e/3d12135a0b60cff5f73ee74213865e7d71a52ef31b00bbb49f\n",
            "Successfully built chesspos\n",
            "Installing collected packages: chesspos\n",
            "Successfully installed chesspos-0.1.2\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pip install tensorflow[and-cuda]\n",
        "%pip install faiss-cpu\n",
        "%pip install h5py\n",
        "%pip install zstandard\n",
        "%pip install python-chess\n",
        "!git clone https://github.com/anirudhajith/chesspos.git\n",
        "!python -m pip install ./chesspos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rr1wysGmHEX-"
      },
      "outputs": [],
      "source": [
        "\"\"\"## Setup imports and globals\"\"\"\n",
        "\n",
        "import chess.pgn\n",
        "import chess\n",
        "import zstandard\n",
        "import os\n",
        "import io\n",
        "from tqdm.auto import tqdm\n",
        "from multiprocessing import Pool, Queue, Manager\n",
        "import pinecone\n",
        "import itertools\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from chesspos.search.binary_index import board_to_bitboard\n",
        "from\n",
        "\n",
        "thread_count = 8\n",
        "start_skip = 0 # Adjust this to skip games in the pgn file\n",
        "\n",
        "def upload_pgn(pgn_file):\n",
        "    pgn_file, mp_queue = pgn_file\n",
        "    model = tf.keras.models.load_model(\"model_encoder.h5\") # Change this to the path of your model\n",
        "    fh = open(pgn_file, \"rb\")\n",
        "    print(\"Processing \" + pgn_file + \"...\")\n",
        "    filesize = os.fstat(fh.fileno()).st_size\n",
        "    dctx = zstandard.ZstdDecompressor()\n",
        "    stream_reader = dctx.stream_reader(fh, read_size=min(1073741824>>6, filesize))\n",
        "    # stream_reader = dctx.stream_reader(fh)\n",
        "    pgn = io.TextIOWrapper(stream_reader)\n",
        "    pbar = tqdm(total=filesize, unit=\"B\", unit_scale=True)\n",
        "\n",
        "    # Start a loop to iterate through all games in the pgn file\n",
        "    game_count = 0\n",
        "    documents = []\n",
        "    boards = []\n",
        "\n",
        "    for i in range(start_skip):\n",
        "        chess.pgn.skip_game(pgn)\n",
        "        game_count += 1\n",
        "        if game_count % 2000 == 0:\n",
        "            pbar.update(fh.tell() - pbar.n)\n",
        "            pbar.set_postfix_str(\"Skipped \" + str(game_count) + \" games\")\n",
        "\n",
        "    while True:\n",
        "        # Read a game from the pgn file\n",
        "        game = chess.pgn.read_game(pgn)\n",
        "        if game is None:\n",
        "            break\n",
        "        game_count += 1\n",
        "        if game_count % 2000 == 0:\n",
        "            # Insert the documents into the database\n",
        "\n",
        "            query = np.array([board_to_bitboard(board) for board in boards])\n",
        "            embeddings = model.predict_on_batch(query)\n",
        "            mp_queue.put((documents, embeddings))\n",
        "            documents.clear()\n",
        "            boards.clear()\n",
        "            pbar.update(fh.tell() - pbar.n)\n",
        "            pbar.set_postfix_str(\"Processed \" + str(game_count) + \" games\")\n",
        "\n",
        "        board = game.board()\n",
        "\n",
        "\n",
        "        for move in game.mainline_moves():\n",
        "            # Extract the board position as a base64 encoded string\n",
        "            board_string = board.fen()\n",
        "            # Extract the move that was made\n",
        "            move_string = move.uci()\n",
        "            # Create a document to insert into the database\n",
        "            boards.append(board.copy(stack=False))\n",
        "            documents.append([ board_string, move_string])\n",
        "            # Make the move on the board\n",
        "            board.push(move)\n",
        "\n",
        "    embeddings = iemb.encode_bitboards(\n",
        "        [board_to_bitboard(board) for board in boards],\n",
        "        model_path=\"deep64/model_encoder.h5\"\n",
        "    )\n",
        "    mp_queue.put((documents, embeddings))\n",
        "\n",
        "    # conn.commit()\n",
        "\n",
        "    # Close the pgn file\n",
        "    pgn.close()\n",
        "\n",
        "    # Print the number of games processed\n",
        "    print(\"Processed \" + str(game_count) + \" games.\")\n",
        "\n",
        "\n",
        "\n",
        "def chunks(iterable, batch_size=100):\n",
        "    \"\"\"A helper function to break an iterable into chunks of size batch_size.\"\"\"\n",
        "    it = iter(iterable)\n",
        "    chunk = tuple(itertools.islice(it, batch_size))\n",
        "    while chunk:\n",
        "        yield chunk\n",
        "        chunk = tuple(itertools.islice(it, batch_size))\n",
        "\n",
        "\n",
        "# Want to run this upload_pgn function for each pgn.\n",
        "def main():\n",
        "    m = Manager()\n",
        "    mp_queue = m.Queue(maxsize=20)\n",
        "\n",
        "\n",
        "    pinecone.init(api_key=\"38132697-8f87-4930-a355-376bd93394a3\", environment=\"us-east4-gcp\")\n",
        "    index = pinecone.Index(\"chesspos-lichess-embeddings\", pool_threads=30)\n",
        "\n",
        "    files = os.listdir(\"pruned2\")\n",
        "    files.sort()\n",
        "    files.reverse()\n",
        "    pgn_files = []\n",
        "    for file in tqdm(files):\n",
        "        if file.endswith(\".zst\"):\n",
        "            pgn_file = \"pruned2/\" + file\n",
        "            pgn_files.append((pgn_file, mp_queue))\n",
        "\n",
        "    # upload_pgn(pgn_files[0])\n",
        "\n",
        "    with Pool(thread_count) as p:\n",
        "        async_res = p.map_async(upload_pgn, pgn_files)\n",
        "\n",
        "        # While there are still results to process\n",
        "        while not async_res.ready() or not async_res.successful():\n",
        "            boards, embeddings = mp_queue.get()\n",
        "            vectors = [(boards[i][0], embeddings[i].tolist(), {\"move\": boards[i][1]}) for i in range(len(boards))]\n",
        "            async_results = [\n",
        "                index.upsert(vectors=ids_vectors_chunk, async_req=True)\n",
        "                for ids_vectors_chunk in chunks(vectors, batch_size=100)\n",
        "            ]\n",
        "            [async_result.get() for async_result in async_results]\n",
        "    index.close()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
